# filepath: /Users/gibran.ghazanfar/Projects/ai-service/app/main.py.fixed
# app/main.py
import os
import logging
import tempfile
import uuid
from contextlib import asynccontextmanager
from datetime import datetime
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Depends
from fastapi.responses import JSONResponse
from sqlalchemy.ext.asyncio import AsyncSession

from app.config import settings
from app.models.request_models import AudioAssessmentRequest, SummarizerRequest
from app.models.response_models import AssessmentResponse, SummaryResponse, RiskLevel
from app.services.speech_service import AlibabaSpeechService
from app.services.qwen_service import QwenService
from app.services.risk_assessment import RiskAssessmentService
from app.services.database_service import DatabaseService
from app.utils.audio_utils import AudioProcessor
from app.database.database import init_database, close_database, get_db, check_database_health
from app.database.repositories import RepositoryManager

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Lifespan event handler for startup and shutdown
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("üöÄ Starting GoShield API...")
    try:
        await init_database()
        logger.info("‚úÖ Database initialized successfully")
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize database: {e}")
        raise
    
    yield
    
    # Shutdown
    logger.info("üõë Shutting down GoShield API...")
    await close_database()
    logger.info("‚úÖ Database connections closed")

app = FastAPI(
    title="GoShield - Ride Safety Pipeline", 
    version="1.0.0",
    lifespan=lifespan
)

# Initialize services
speech_service = AlibabaSpeechService()
qwen_service = QwenService()
risk_service = RiskAssessmentService()

# Ensure temp directory exists
os.makedirs(settings.AUDIO_TEMP_DIR, exist_ok=True)

@app.get("/")
async def root():
    return {"message": "GoShield API is running", "version": "1.0.0"}

@app.get("/health")
async def health_check():
    """Health check endpoint with database status"""
    db_healthy = await check_database_health()
    
    return {
        "status": "healthy" if db_healthy else "unhealthy",
        "database": "connected" if db_healthy else "disconnected",
        "version": "1.0.0",
        "service": "GoShield AI Service"
    }

@app.post("/api/assessment", response_model=AssessmentResponse)
async def assess_audio_risk(
    audio_file: UploadFile = File(...),
    driver_id: str = Form(None),
    location_lat: float = Form(None),
    location_lng: float = Form(None),
    route_expected: str = Form(None),
    db: AsyncSession = Depends(get_db)
):
    """
    Main assessment API - takes 10-second audio slice and returns risk assessment
    """
    assessment_id = str(uuid.uuid4())
    repo = RepositoryManager(db)
    
    try:
        # Log the assessment request
        await repo.logs.log(
            level="INFO",
            service="assessment_api",
            message=f"Starting audio assessment for driver: {driver_id}",
            context={
                "assessment_id": assessment_id,
                "driver_id": driver_id,
                "location": {"lat": location_lat, "lng": location_lng} if location_lat and location_lng else None
            }
        )
        
        # Save uploaded audio temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav", 
                                       dir=settings.AUDIO_TEMP_DIR) as temp_file:
            content = await audio_file.read()
            temp_file.write(content)
            temp_audio_path = temp_file.name
        
        try:
            # Step 1: Transcribe audio
            logger.info("Transcribing audio...")
            transcribed_text = speech_service.transcribe_audio(temp_audio_path)
            
            if not transcribed_text:
                logger.warning("No speech detected in audio")
                transcribed_text = "[No speech detected]"
            
            # Step 2: Assess threat level from text
            logger.info("Assessing threat level...")
            threat_text_score = qwen_service.assess_threat_level(transcribed_text)
            
            # Step 3: Calculate location risk
            location_risk = risk_service.calculate_location_risk(
                location_lat, location_lng, route_expected
            )
            
            # Step 4: Get driver history score
            driver_history_score = risk_service.get_driver_history_score(driver_id)
            
            # Step 5: Calculate overall risk
            overall_score, risk_level = risk_service.calculate_overall_risk(
                threat_text_score, location_risk, driver_history_score
            )
            
            # Step 6: Determine actions
            action_required = risk_level in [RiskLevel.MEDIUM, RiskLevel.HIGH]
            push_notification = risk_service.get_push_notification_message(risk_level) if action_required else None
            
            # Step 7: Store assessment in database
            assessment_data = {
                "assessment_id": assessment_id,
                "driver_id": driver_id,
                "audio_file_path": temp_audio_path,
                "audio_duration_seconds": 10.0,  # Assuming 10-second clips
                "audio_format": audio_file.content_type,
                "location_lat": location_lat,
                "location_lng": location_lng,
                "route_expected": route_expected,
                "transcribed_text": transcribed_text,
                "transcription_confidence": 0.9,  # TODO: Get actual confidence from speech service
                "risk_score": overall_score,
                "risk_level": risk_level,
                "threat_text_score": threat_text_score,
                "location_risk_index": location_risk,
                "driver_history_score": driver_history_score,
                "action_required": action_required,
                "push_notification": push_notification
            }
            
            # Save assessment
            assessment = await repo.assessments.create_assessment(assessment_data)
            
            # Update driver risk score if we have a driver_id
            if driver_id:
                await repo.drivers.update_driver_risk_score(driver_id, driver_history_score)
            
            # Update location risk if we have coordinates
            if location_lat and location_lng:
                await repo.locations.update_location_risk(location_lat, location_lng, location_risk)
            
            logger.info(f"Risk assessment completed and stored: {risk_level.value} ({overall_score:.2f})")
            
            # Log successful completion
            await repo.logs.log(
                level="INFO",
                service="assessment_api",
                message=f"Assessment completed successfully",
                context={
                    "assessment_id": assessment_id,
                    "risk_level": risk_level.value,
                    "risk_score": overall_score,
                    "action_required": action_required
                }
            )
            
            return AssessmentResponse(
                risk_score=overall_score,
                risk_level=risk_level,
                threat_text_score=threat_text_score,
                location_risk_index=location_risk,
                driver_history_score=driver_history_score,
                transcribed_text=transcribed_text,
                action_required=action_required,
                push_notification=push_notification
            )
            
        finally:
            # Clean up temp file
            if os.path.exists(temp_audio_path):
                os.unlink(temp_audio_path)
        
    except Exception as e:
        logger.error(f"Error in risk assessment: {e}")
        await repo.logs.log(
            level="ERROR",
            service="assessment_api",
            message=f"Assessment failed: {str(e)}",
            context={"assessment_id": assessment_id}
        )
        raise HTTPException(status_code=500, detail=f"Assessment failed: {str(e)}")

# app/main.py (summarize endpoint)
@app.post("/api/summarize")
async def create_evidence_kit(
    audio_file: UploadFile = File(...),
    incident_id: str = Form(None),
    ride_id: str = Form(None),
    passenger_id: str = Form(None),
    driver_id: str = Form(None),
    additional_context: str = Form(None),
    db: AsyncSession = Depends(get_db)
):
    """
    Create Evidence Kit from Audio File
    - Transcribes audio using Alibaba ISI
    - Performs comprehensive threat analysis using Qwen
    - Creates structured evidence kit as JSON
    - Stores incident in database
    """
    db_service = DatabaseService(db)
    evidence_kit_id = str(uuid.uuid4())
    temp_audio_path = None
    
    try:
        # Log the evidence kit creation request
        await db_service.log_system_event(
            level="INFO",
            service="evidence_kit_api",
            message=f"Starting evidence kit creation",
            context={
                "evidence_kit_id": evidence_kit_id,
                "incident_id": incident_id,
                "driver_id": driver_id,
                "filename": audio_file.filename
            }
        )
        
        # Validate file format
        if not AudioProcessor.is_supported_format(audio_file.filename):
            raise HTTPException(
                status_code=400, 
                detail=f"Unsupported audio format. Supported: {AudioProcessor.SUPPORTED_FORMATS}"
            )
        
        # Determine file extension
        file_ext = os.path.splitext(audio_file.filename)[1] or '.wav'
        
        # Save uploaded audio temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext, 
                                       dir=settings.AUDIO_TEMP_DIR) as temp_file:
            content = await audio_file.read()
            temp_file.write(content)
            temp_audio_path = temp_file.name
        
        try:
            logger.info(f"Creating evidence kit for {audio_file.filename}")
            
            # Step 1: Get audio information
            audio_info = AudioProcessor.get_audio_info(temp_audio_path)
            audio_duration = audio_info.get('duration_seconds', 0)
            
            # Step 2: Transcribe audio
            logger.info("Transcribing audio for evidence kit...")
            transcribed_text = speech_service.transcribe_audio(temp_audio_path)
            
            if not transcribed_text:
                logger.warning("No speech detected in audio")
                transcribed_text = "[No clear speech detected in audio file]"
            
            logger.info(f"Transcription completed: {len(transcribed_text)} characters")
            
            # Step 3: Perform basic threat assessment for context
            threat_score = qwen_service.assess_threat_level(transcribed_text)
            
            # Step 4: Create risk assessment context
            risk_assessment = {
                "threat_text_score": threat_score,
                "overall_score": threat_score,  # Simplified for evidence kit
                "assessment_type": "full_audio_analysis",
                "processing_method": "comprehensive_review"
            }
            
            # Step 5: Prepare ride context
            ride_context = {
                "incident_id": incident_id,
                "ride_id": ride_id,
                "passenger_id": passenger_id,
                "driver_id": driver_id,
                "additional_context": additional_context,
                "audio_filename": audio_file.filename,
                "file_size_bytes": len(content)
            }
            
            # Step 6: Create comprehensive evidence kit
            logger.info("Generating comprehensive evidence kit...")
            evidence_kit = qwen_service.create_evidence_kit(
                transcript=transcribed_text,
                audio_duration=audio_duration,
                risk_assessment=risk_assessment,
                ride_context=ride_context
            )
            
            # Step 7: Store incident in database
            if evidence_kit:
                incident_data = {
                    "incident_id": incident_id or str(uuid.uuid4()),
                    "evidence_kit_id": evidence_kit_id,
                    "ride_id": ride_id,
                    "passenger_id": passenger_id,
                    "driver_id": driver_id,
                    "audio_file_path": temp_audio_path,
                    "audio_duration_seconds": audio_duration,
                    "full_transcript": transcribed_text,
                    "primary_category": evidence_kit.get("incident_classification", {}).get("primary_category", "Unknown"),
                    "secondary_categories": evidence_kit.get("incident_classification", {}).get("secondary_categories", []),
                    "severity_level": evidence_kit.get("incident_classification", {}).get("severity_level", "MEDIUM"),
                    "urgency": evidence_kit.get("incident_classification", {}).get("urgency", "MEDIUM"),
                    "requires_immediate_action": evidence_kit.get("incident_classification", {}).get("requires_immediate_action", False),
                    "executive_summary": evidence_kit.get("executive_summary", ""),
                    "risk_assessment": risk_assessment,
                    "recommended_actions": evidence_kit.get("recommended_actions", []),
                    "follow_up_required": evidence_kit.get("follow_up_required", False),
                    "overall_risk_score": threat_score,
                    "confidence_level": evidence_kit.get("confidence_level", 0.8)
                }
                
                stored_incident_id = await db_service.create_incident(incident_data)
                evidence_kit["stored_incident_id"] = stored_incident_id
            
            logger.info(f"Evidence kit created and stored successfully: {evidence_kit_id}")
            
            # Log successful completion
            await db_service.log_system_event(
                level="INFO",
                service="evidence_kit_api",
                message="Evidence kit created successfully",
                context={
                    "evidence_kit_id": evidence_kit_id,
                    "incident_id": evidence_kit.get("stored_incident_id"),
                    "audio_duration": audio_duration,
                    "threat_score": threat_score
                }
            )
            
            return evidence_kit
            
        finally:
            # Clean up temp file
            if os.path.exists(temp_audio_path):
                os.unlink(temp_audio_path)
        
    except Exception as e:
        logger.error(f"Error creating evidence kit: {e}", exc_info=True)
        await db_service.log_system_event(
            level="ERROR",
            service="evidence_kit_api",
            message=f"Evidence kit creation failed: {str(e)}",
            context={"evidence_kit_id": evidence_kit_id}
        )
        raise HTTPException(status_code=500, detail=f"Evidence kit creation failed: {str(e)}")

# Also add a simplified endpoint for just transcript extraction
@app.post("/api/transcribe")
async def transcribe_audio_only(audio_file: UploadFile = File(...)):
    """
    Simple endpoint to just get transcript from audio
    """
    temp_audio_path = None
    
    try:
        if not AudioProcessor.is_supported_format(audio_file.filename):
            raise HTTPException(
                status_code=400, 
                detail=f"Unsupported audio format. Supported: {AudioProcessor.SUPPORTED_FORMATS}"
            )
        
        file_ext = os.path.splitext(audio_file.filename)[1] or '.wav'
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext, 
                                       dir=settings.AUDIO_TEMP_DIR) as temp_file:
            content = await audio_file.read()
            temp_file.write(content)
            temp_audio_path = temp_file.name
        
        try:
            audio_info = AudioProcessor.get_audio_info(temp_audio_path)
            transcribed_text = speech_service.transcribe_audio(temp_audio_path)
            
            return {
                "transcript": transcribed_text or "[No speech detected]",
                "audio_info": audio_info,
                "filename": audio_file.filename,
                "processing_timestamp": datetime.now().isoformat()
            }
            
        finally:
            if os.path.exists(temp_audio_path):
                os.unlink(temp_audio_path)
        
    except Exception as e:
        logger.error(f"Error in transcription: {e}")
        raise HTTPException(status_code=500, detail=f"Transcription failed: {str(e)}")      

if __name__ == "__main__":
    try:
        import uvicorn
        uvicorn.run(app, host="0.0.0.0", port=8000)
    except ImportError:
        logger.error("Uvicorn not installed. Cannot run the app directly.")
